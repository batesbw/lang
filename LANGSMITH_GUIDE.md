# LangSmith Tracing Guide for Salesforce Agent Workforce

This guide provides a brief overview of how to access and interpret LangSmith traces for monitoring and debugging the Salesforce Agent Workforce.

## 1. Accessing LangSmith

*   **Login**: Navigate to [LangSmith](https://smith.langchain.com/) and log in with your credentials.
*   **Select Project**: Once logged in, select the project created for this workforce (e.g., "Salesforce Agent Workforce" or the name you chose).

## 2. Understanding Traces

When the agents and their LangGraph orchestrator run, they will automatically send trace data to LangSmith, provided the environment variables (`LANGCHAIN_TRACING_V2`, `LANGCHAIN_ENDPOINT`, `LANGCHAIN_API_KEY`, `LANGCHAIN_PROJECT`) are correctly configured.

### Key Components of a Trace:

*   **Runs**: Each execution of an agent, a tool, an LLM call, or the entire graph is considered a "run." You'll see a list of these runs in your project.
    *   **Parent Runs**: The overall execution of the LangGraph orchestrator will be a top-level parent run.
    *   **Child Runs**: Individual agent invocations, tool executions, and LLM calls within that orchestration will appear as child runs, nested under their respective parent. This creates a hierarchical view of the execution flow.

*   **Run Details**: Clicking on a specific run will show you:
    *   **Inputs**: The inputs provided to that component (e.g., prompt to an LLM, arguments to a tool).
    *   **Outputs**: The outputs generated by that component (e.g., LLM response, tool result, agent's final answer).
    *   **Timestamps & Duration**: When the run started, ended, and how long it took. This is crucial for identifying performance bottlenecks.
    *   **Tokens (for LLMs)**: Token usage for LLM calls, helping monitor costs and efficiency.
    *   **Error Messages**: If a run failed, the error message and stack trace (if available) will be displayed. This is invaluable for debugging.
    *   **Metadata**: Any custom metadata attached to the run (we can add this programmatically for better context).
    *   **Tags**: Tags can be used to categorize or filter runs.

### Interpreting Traces for Debugging & Monitoring:

1.  **Overall Flow**: Look at the parent run for the orchestrator to understand the sequence of agent calls and how data flows between them.
2.  **Agent Performance**:
    *   Check the duration of each agent's run.
    *   Examine the inputs to an agent to ensure it's receiving the correct information.
    *   Analyze the outputs to see if the agent is producing the expected results or state changes.
3.  **Tool Usage**:
    *   Drill down into tool runs used by agents.
    *   Verify the arguments passed to tools and the results they return.
    *   Errors within tools are often a common source of problems.
4.  **LLM Calls**:
    *   Inspect the exact prompts being sent to the LLMs.
    *   Review the LLM's raw responses. This can help in prompt engineering if the LLM is not behaving as expected.
    *   Monitor token counts.
5.  **Error Analysis**:
    *   When an error occurs, LangSmith will usually highlight the failed run.
    *   Start from the failed run and work your way up the hierarchy to understand the context in which the error happened.
6.  **Feedback & Annotation**:
    *   LangSmith allows you to add feedback (e.g., marking a trace as a "good" or "bad" example) and annotations. This is useful for curating datasets for evaluation or fine-tuning later.

## Best Practices:

*   **Regularly Monitor**: Especially during development and after deploying new changes.
*   **Filter and Search**: Use LangSmith's filtering and search capabilities to quickly find specific traces (e.g., by error, by a specific agent, or by tags).
*   **Correlate with Code**: When debugging, have your codebase open to correlate the traced operations with the actual agent and tool implementations.

This guide provides a starting point. LangSmith has more advanced features (like datasets, evaluators, and monitoring dashboards) that can be explored as the project matures. 